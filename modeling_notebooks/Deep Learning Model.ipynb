{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (0.0)\r\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (from sklearn) (0.23.2)\r\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.5.2)\r\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (2.1.0)\r\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (0.17.0)\r\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.19.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/leah/opt/anaconda3/lib/python3.8/site-packages (0.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6983</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.513523</td>\n",
       "      <td>2.714000e-04</td>\n",
       "      <td>-2.714000e-04</td>\n",
       "      <td>132.335600</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>...</td>\n",
       "      <td>-141</td>\n",
       "      <td>3.508</td>\n",
       "      <td>0.187</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>3.318</td>\n",
       "      <td>0.665</td>\n",
       "      <td>-0.813</td>\n",
       "      <td>287.46786</td>\n",
       "      <td>37.966640</td>\n",
       "      <td>10.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>1.846000e-04</td>\n",
       "      <td>-1.846000e-04</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>...</td>\n",
       "      <td>-152</td>\n",
       "      <td>4.296</td>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>1.160000e-07</td>\n",
       "      <td>-1.160000e-07</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>-166</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.196</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>2.430000e-06</td>\n",
       "      <td>-2.430000e-06</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>...</td>\n",
       "      <td>-236</td>\n",
       "      <td>4.447</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>6.360000e-05</td>\n",
       "      <td>-6.360000e-05</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>...</td>\n",
       "      <td>-225</td>\n",
       "      <td>4.385</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5304 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "0          CONFIRMED              0              0              0   \n",
       "1     FALSE POSITIVE              0              1              0   \n",
       "2     FALSE POSITIVE              0              1              0   \n",
       "3          CONFIRMED              0              0              0   \n",
       "4          CONFIRMED              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "6983  FALSE POSITIVE              0              1              0   \n",
       "6986  FALSE POSITIVE              0              0              0   \n",
       "6987  FALSE POSITIVE              0              1              1   \n",
       "6989  FALSE POSITIVE              0              0              1   \n",
       "6990  FALSE POSITIVE              0              0              1   \n",
       "\n",
       "      koi_fpflag_ec  koi_period  koi_period_err1  koi_period_err2  \\\n",
       "0                 0   54.418383     2.479000e-04    -2.479000e-04   \n",
       "1                 0   19.899140     1.490000e-05    -1.490000e-05   \n",
       "2                 0    1.736952     2.630000e-07    -2.630000e-07   \n",
       "3                 0    2.525592     3.760000e-06    -3.760000e-06   \n",
       "4                 0    4.134435     1.050000e-05    -1.050000e-05   \n",
       "...             ...         ...              ...              ...   \n",
       "6983              0   21.513523     2.714000e-04    -2.714000e-04   \n",
       "6986              1    8.589871     1.846000e-04    -1.846000e-04   \n",
       "6987              0    0.527699     1.160000e-07    -1.160000e-07   \n",
       "6989              0    0.681402     2.430000e-06    -2.430000e-06   \n",
       "6990              1    4.856035     6.360000e-05    -6.360000e-05   \n",
       "\n",
       "      koi_time0bk  koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  \\\n",
       "0      162.513840          0.003520  ...             -81      4.467   \n",
       "1      175.850252          0.000581  ...            -176      4.544   \n",
       "2      170.307565          0.000115  ...            -174      4.564   \n",
       "3      171.595550          0.001130  ...            -211      4.438   \n",
       "4      172.979370          0.001900  ...            -232      4.486   \n",
       "...           ...               ...  ...             ...        ...   \n",
       "6983   132.335600          0.012200  ...            -141      3.508   \n",
       "6986   132.016100          0.015700  ...            -152      4.296   \n",
       "6987   131.705093          0.000170  ...            -166      4.529   \n",
       "6989   132.181750          0.002850  ...            -236      4.447   \n",
       "6990   135.993300          0.010800  ...            -225      4.385   \n",
       "\n",
       "      koi_slogg_err1  koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2  \\\n",
       "0              0.064          -0.096     0.927          0.105         -0.061   \n",
       "1              0.044          -0.176     0.868          0.233         -0.078   \n",
       "2              0.053          -0.168     0.791          0.201         -0.067   \n",
       "3              0.070          -0.210     1.046          0.334         -0.133   \n",
       "4              0.054          -0.229     0.972          0.315         -0.105   \n",
       "...              ...             ...       ...            ...            ...   \n",
       "6983           0.187          -0.153     3.318          0.665         -0.813   \n",
       "6986           0.231          -0.189     1.088          0.313         -0.228   \n",
       "6987           0.035          -0.196     0.903          0.237         -0.079   \n",
       "6989           0.056          -0.224     1.041          0.341         -0.114   \n",
       "6990           0.054          -0.216     1.193          0.410         -0.137   \n",
       "\n",
       "             ra        dec  koi_kepmag  \n",
       "0     291.93423  48.141651      15.347  \n",
       "1     297.00482  48.134129      15.436  \n",
       "2     285.53461  48.285210      15.597  \n",
       "3     288.75488  48.226200      15.509  \n",
       "4     296.28613  48.224670      15.714  \n",
       "...         ...        ...         ...  \n",
       "6983  287.46786  37.966640      10.630  \n",
       "6986  298.74921  46.973351      14.478  \n",
       "6987  297.18875  47.093819      14.082  \n",
       "6989  294.16489  47.176281      15.385  \n",
       "6990  297.00977  47.121021      14.826  \n",
       "\n",
       "[5304 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known = df.loc[df[\"koi_disposition\"]!=\"CANDIDATE\",:]\n",
    "known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation of column names: https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = known[['koi_slogg', 'koi_steff', 'koi_srad', 'koi_depth', 'koi_prad','koi_duration','koi_period','koi_teq','koi_insol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            CONFIRMED\n",
       "1       FALSE POSITIVE\n",
       "2       FALSE POSITIVE\n",
       "3            CONFIRMED\n",
       "4            CONFIRMED\n",
       "             ...      \n",
       "6983    FALSE POSITIVE\n",
       "6986    FALSE POSITIVE\n",
       "6987    FALSE POSITIVE\n",
       "6989    FALSE POSITIVE\n",
       "6990    FALSE POSITIVE\n",
       "Name: koi_disposition, Length: 5304, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=known[\"koi_disposition\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_features, results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# got code for using grid search with a deep learning model here: \n",
    "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching on batch size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, activation='relu', input_dim=9))\n",
    "    model.add(Dense(units=20, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [5, 10, 20]\n",
    "epochs = [50,100,200]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  27 | elapsed:  4.1min remaining:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "796/796 [==============================] - 1s 733us/step - loss: 0.5953 - accuracy: 0.6849\n",
      "Epoch 2/200\n",
      "796/796 [==============================] - 1s 740us/step - loss: 0.4789 - accuracy: 0.7502\n",
      "Epoch 3/200\n",
      "796/796 [==============================] - 1s 705us/step - loss: 0.4631 - accuracy: 0.7571\n",
      "Epoch 4/200\n",
      "796/796 [==============================] - 1s 765us/step - loss: 0.4246 - accuracy: 0.7892\n",
      "Epoch 5/200\n",
      "796/796 [==============================] - 1s 729us/step - loss: 0.4388 - accuracy: 0.7848\n",
      "Epoch 6/200\n",
      "796/796 [==============================] - 1s 717us/step - loss: 0.4192 - accuracy: 0.7965\n",
      "Epoch 7/200\n",
      "796/796 [==============================] - 1s 735us/step - loss: 0.4377 - accuracy: 0.7891\n",
      "Epoch 8/200\n",
      "796/796 [==============================] - 1s 726us/step - loss: 0.4151 - accuracy: 0.8116\n",
      "Epoch 9/200\n",
      "796/796 [==============================] - 1s 690us/step - loss: 0.4136 - accuracy: 0.8068\n",
      "Epoch 10/200\n",
      "796/796 [==============================] - 1s 678us/step - loss: 0.4122 - accuracy: 0.8078\n",
      "Epoch 11/200\n",
      "796/796 [==============================] - 1s 681us/step - loss: 0.4173 - accuracy: 0.8055\n",
      "Epoch 12/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.4039 - accuracy: 0.8105\n",
      "Epoch 13/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.3959 - accuracy: 0.8214\n",
      "Epoch 14/200\n",
      "796/796 [==============================] - 1s 690us/step - loss: 0.3930 - accuracy: 0.8236\n",
      "Epoch 15/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.3990 - accuracy: 0.8186\n",
      "Epoch 16/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3739 - accuracy: 0.8301\n",
      "Epoch 17/200\n",
      "796/796 [==============================] - 1s 650us/step - loss: 0.3831 - accuracy: 0.8238\n",
      "Epoch 18/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.3789 - accuracy: 0.8301\n",
      "Epoch 19/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.3648 - accuracy: 0.8380\n",
      "Epoch 20/200\n",
      "796/796 [==============================] - 1s 676us/step - loss: 0.3797 - accuracy: 0.8252\n",
      "Epoch 21/200\n",
      "796/796 [==============================] - 1s 713us/step - loss: 0.3579 - accuracy: 0.8411\n",
      "Epoch 22/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.3791 - accuracy: 0.8211\n",
      "Epoch 23/200\n",
      "796/796 [==============================] - 1s 670us/step - loss: 0.3693 - accuracy: 0.8261\n",
      "Epoch 24/200\n",
      "796/796 [==============================] - 1s 668us/step - loss: 0.3548 - accuracy: 0.8365\n",
      "Epoch 25/200\n",
      "796/796 [==============================] - 1s 655us/step - loss: 0.3415 - accuracy: 0.8498\n",
      "Epoch 26/200\n",
      "796/796 [==============================] - 1s 655us/step - loss: 0.3539 - accuracy: 0.8412\n",
      "Epoch 27/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3521 - accuracy: 0.8441\n",
      "Epoch 28/200\n",
      "796/796 [==============================] - 1s 649us/step - loss: 0.3404 - accuracy: 0.8476\n",
      "Epoch 29/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.3486 - accuracy: 0.8469\n",
      "Epoch 30/200\n",
      "796/796 [==============================] - 1s 650us/step - loss: 0.3504 - accuracy: 0.8467\n",
      "Epoch 31/200\n",
      "796/796 [==============================] - 1s 641us/step - loss: 0.3460 - accuracy: 0.8434\n",
      "Epoch 32/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.3361 - accuracy: 0.8482\n",
      "Epoch 33/200\n",
      "796/796 [==============================] - 1s 675us/step - loss: 0.3298 - accuracy: 0.8502\n",
      "Epoch 34/200\n",
      "796/796 [==============================] - 1s 649us/step - loss: 0.3442 - accuracy: 0.8527\n",
      "Epoch 35/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3272 - accuracy: 0.8475\n",
      "Epoch 36/200\n",
      "796/796 [==============================] - 1s 641us/step - loss: 0.3380 - accuracy: 0.8457\n",
      "Epoch 37/200\n",
      "796/796 [==============================] - 1s 655us/step - loss: 0.3340 - accuracy: 0.8544\n",
      "Epoch 38/200\n",
      "796/796 [==============================] - 1s 633us/step - loss: 0.3393 - accuracy: 0.8474\n",
      "Epoch 39/200\n",
      "796/796 [==============================] - 1s 646us/step - loss: 0.3313 - accuracy: 0.8538\n",
      "Epoch 40/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3228 - accuracy: 0.8587\n",
      "Epoch 41/200\n",
      "796/796 [==============================] - 1s 668us/step - loss: 0.3429 - accuracy: 0.8411\n",
      "Epoch 42/200\n",
      "796/796 [==============================] - 1s 668us/step - loss: 0.3198 - accuracy: 0.8581\n",
      "Epoch 43/200\n",
      "796/796 [==============================] - 1s 641us/step - loss: 0.3275 - accuracy: 0.8554\n",
      "Epoch 44/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.3195 - accuracy: 0.8598\n",
      "Epoch 45/200\n",
      "796/796 [==============================] - 1s 651us/step - loss: 0.3085 - accuracy: 0.8679\n",
      "Epoch 46/200\n",
      "796/796 [==============================] - 1s 639us/step - loss: 0.3280 - accuracy: 0.8623\n",
      "Epoch 47/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.3203 - accuracy: 0.8593\n",
      "Epoch 48/200\n",
      "796/796 [==============================] - 1s 643us/step - loss: 0.3326 - accuracy: 0.8528\n",
      "Epoch 49/200\n",
      "796/796 [==============================] - 1s 651us/step - loss: 0.3354 - accuracy: 0.8556\n",
      "Epoch 50/200\n",
      "796/796 [==============================] - 1s 673us/step - loss: 0.3212 - accuracy: 0.8546\n",
      "Epoch 51/200\n",
      "796/796 [==============================] - 1s 677us/step - loss: 0.3167 - accuracy: 0.8611\n",
      "Epoch 52/200\n",
      "796/796 [==============================] - 1s 673us/step - loss: 0.3365 - accuracy: 0.8566\n",
      "Epoch 53/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.3267 - accuracy: 0.8566\n",
      "Epoch 54/200\n",
      "796/796 [==============================] - 1s 639us/step - loss: 0.3209 - accuracy: 0.8523\n",
      "Epoch 55/200\n",
      "796/796 [==============================] - 1s 637us/step - loss: 0.3247 - accuracy: 0.8564\n",
      "Epoch 56/200\n",
      "796/796 [==============================] - 1s 666us/step - loss: 0.3206 - accuracy: 0.8627\n",
      "Epoch 57/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3246 - accuracy: 0.8561\n",
      "Epoch 58/200\n",
      "796/796 [==============================] - 1s 885us/step - loss: 0.3102 - accuracy: 0.8644\n",
      "Epoch 59/200\n",
      "796/796 [==============================] - 1s 859us/step - loss: 0.3260 - accuracy: 0.8542\n",
      "Epoch 60/200\n",
      "796/796 [==============================] - 1s 944us/step - loss: 0.3036 - accuracy: 0.8702\n",
      "Epoch 61/200\n",
      "796/796 [==============================] - 1s 926us/step - loss: 0.3045 - accuracy: 0.8742\n",
      "Epoch 62/200\n",
      "796/796 [==============================] - 1s 913us/step - loss: 0.3068 - accuracy: 0.8674\n",
      "Epoch 63/200\n",
      "796/796 [==============================] - 1s 888us/step - loss: 0.3175 - accuracy: 0.8512\n",
      "Epoch 64/200\n",
      "796/796 [==============================] - 1s 925us/step - loss: 0.3207 - accuracy: 0.8602\n",
      "Epoch 65/200\n",
      "796/796 [==============================] - 1s 955us/step - loss: 0.3120 - accuracy: 0.8558\n",
      "Epoch 66/200\n",
      "796/796 [==============================] - 1s 745us/step - loss: 0.3253 - accuracy: 0.8543\n",
      "Epoch 67/200\n",
      "796/796 [==============================] - 1s 636us/step - loss: 0.3056 - accuracy: 0.8688\n",
      "Epoch 68/200\n",
      "796/796 [==============================] - 1s 671us/step - loss: 0.3149 - accuracy: 0.8572\n",
      "Epoch 69/200\n",
      "796/796 [==============================] - 1s 650us/step - loss: 0.3128 - accuracy: 0.8654\n",
      "Epoch 70/200\n",
      "796/796 [==============================] - 1s 639us/step - loss: 0.3155 - accuracy: 0.8612\n",
      "Epoch 71/200\n",
      "796/796 [==============================] - 1s 631us/step - loss: 0.3049 - accuracy: 0.8683\n",
      "Epoch 72/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.3241 - accuracy: 0.8598\n",
      "Epoch 73/200\n",
      "796/796 [==============================] - 1s 692us/step - loss: 0.3217 - accuracy: 0.8533\n",
      "Epoch 74/200\n",
      "796/796 [==============================] - 1s 676us/step - loss: 0.3137 - accuracy: 0.8692\n",
      "Epoch 75/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.3128 - accuracy: 0.8612\n",
      "Epoch 76/200\n",
      "796/796 [==============================] - 1s 643us/step - loss: 0.3272 - accuracy: 0.8559\n",
      "Epoch 77/200\n",
      "796/796 [==============================] - 1s 651us/step - loss: 0.3199 - accuracy: 0.8561\n",
      "Epoch 78/200\n",
      "796/796 [==============================] - 1s 657us/step - loss: 0.3396 - accuracy: 0.8576\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 1s 646us/step - loss: 0.3266 - accuracy: 0.8521\n",
      "Epoch 80/200\n",
      "796/796 [==============================] - 1s 664us/step - loss: 0.3083 - accuracy: 0.8723\n",
      "Epoch 81/200\n",
      "796/796 [==============================] - 1s 664us/step - loss: 0.2980 - accuracy: 0.8618\n",
      "Epoch 82/200\n",
      "796/796 [==============================] - 1s 686us/step - loss: 0.3058 - accuracy: 0.8630\n",
      "Epoch 83/200\n",
      "796/796 [==============================] - 1s 671us/step - loss: 0.3004 - accuracy: 0.8701\n",
      "Epoch 84/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3209 - accuracy: 0.8549\n",
      "Epoch 85/200\n",
      "796/796 [==============================] - 1s 634us/step - loss: 0.3074 - accuracy: 0.8618\n",
      "Epoch 86/200\n",
      "796/796 [==============================] - 1s 681us/step - loss: 0.3181 - accuracy: 0.8571\n",
      "Epoch 87/200\n",
      "796/796 [==============================] - 1s 708us/step - loss: 0.3041 - accuracy: 0.8654\n",
      "Epoch 88/200\n",
      "796/796 [==============================] - 1s 677us/step - loss: 0.3142 - accuracy: 0.8580\n",
      "Epoch 89/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.3184 - accuracy: 0.8549\n",
      "Epoch 90/200\n",
      "796/796 [==============================] - 1s 632us/step - loss: 0.3227 - accuracy: 0.8639\n",
      "Epoch 91/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.3082 - accuracy: 0.8611\n",
      "Epoch 92/200\n",
      "796/796 [==============================] - 1s 646us/step - loss: 0.3173 - accuracy: 0.8582\n",
      "Epoch 93/200\n",
      "796/796 [==============================] - 1s 663us/step - loss: 0.3052 - accuracy: 0.8738\n",
      "Epoch 94/200\n",
      "796/796 [==============================] - 1s 654us/step - loss: 0.3125 - accuracy: 0.8610\n",
      "Epoch 95/200\n",
      "796/796 [==============================] - 1s 660us/step - loss: 0.3101 - accuracy: 0.8599\n",
      "Epoch 96/200\n",
      "796/796 [==============================] - 1s 656us/step - loss: 0.3183 - accuracy: 0.8539\n",
      "Epoch 97/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3123 - accuracy: 0.8672\n",
      "Epoch 98/200\n",
      "796/796 [==============================] - 1s 634us/step - loss: 0.2985 - accuracy: 0.8695\n",
      "Epoch 99/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3251 - accuracy: 0.8591\n",
      "Epoch 100/200\n",
      "796/796 [==============================] - 1s 635us/step - loss: 0.3056 - accuracy: 0.8659\n",
      "Epoch 101/200\n",
      "796/796 [==============================] - 1s 635us/step - loss: 0.3097 - accuracy: 0.8662\n",
      "Epoch 102/200\n",
      "796/796 [==============================] - 1s 637us/step - loss: 0.3131 - accuracy: 0.8636\n",
      "Epoch 103/200\n",
      "796/796 [==============================] - 1s 681us/step - loss: 0.3195 - accuracy: 0.8563\n",
      "Epoch 104/200\n",
      "796/796 [==============================] - 1s 634us/step - loss: 0.3034 - accuracy: 0.8648\n",
      "Epoch 105/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.2946 - accuracy: 0.8657\n",
      "Epoch 106/200\n",
      "796/796 [==============================] - 1s 632us/step - loss: 0.3076 - accuracy: 0.8633\n",
      "Epoch 107/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.3050 - accuracy: 0.8637\n",
      "Epoch 108/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.3064 - accuracy: 0.8608\n",
      "Epoch 109/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.2970 - accuracy: 0.8738\n",
      "Epoch 110/200\n",
      "796/796 [==============================] - 1s 636us/step - loss: 0.3062 - accuracy: 0.8659\n",
      "Epoch 111/200\n",
      "796/796 [==============================] - 1s 635us/step - loss: 0.3030 - accuracy: 0.8621\n",
      "Epoch 112/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.2957 - accuracy: 0.8699\n",
      "Epoch 113/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3119 - accuracy: 0.8579\n",
      "Epoch 114/200\n",
      "796/796 [==============================] - 1s 629us/step - loss: 0.2994 - accuracy: 0.8730\n",
      "Epoch 115/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.2980 - accuracy: 0.8676\n",
      "Epoch 116/200\n",
      "796/796 [==============================] - 1s 634us/step - loss: 0.3006 - accuracy: 0.8625\n",
      "Epoch 117/200\n",
      "796/796 [==============================] - 1s 669us/step - loss: 0.3048 - accuracy: 0.8623\n",
      "Epoch 118/200\n",
      "796/796 [==============================] - 1s 655us/step - loss: 0.3063 - accuracy: 0.8694\n",
      "Epoch 119/200\n",
      "796/796 [==============================] - 1s 643us/step - loss: 0.2970 - accuracy: 0.8664\n",
      "Epoch 120/200\n",
      "796/796 [==============================] - 1s 640us/step - loss: 0.3069 - accuracy: 0.8634\n",
      "Epoch 121/200\n",
      "796/796 [==============================] - 1s 651us/step - loss: 0.3063 - accuracy: 0.8622\n",
      "Epoch 122/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.3031 - accuracy: 0.8686\n",
      "Epoch 123/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.2989 - accuracy: 0.8703\n",
      "Epoch 124/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3226 - accuracy: 0.8547\n",
      "Epoch 125/200\n",
      "796/796 [==============================] - 1s 672us/step - loss: 0.3098 - accuracy: 0.8633\n",
      "Epoch 126/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.3063 - accuracy: 0.8585\n",
      "Epoch 127/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.3055 - accuracy: 0.8688\n",
      "Epoch 128/200\n",
      "796/796 [==============================] - 1s 646us/step - loss: 0.3041 - accuracy: 0.8720\n",
      "Epoch 129/200\n",
      "796/796 [==============================] - 1s 642us/step - loss: 0.2900 - accuracy: 0.8763\n",
      "Epoch 130/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.3018 - accuracy: 0.8714\n",
      "Epoch 131/200\n",
      "796/796 [==============================] - 1s 640us/step - loss: 0.2886 - accuracy: 0.8822\n",
      "Epoch 132/200\n",
      "796/796 [==============================] - 1s 668us/step - loss: 0.3081 - accuracy: 0.8638\n",
      "Epoch 133/200\n",
      "796/796 [==============================] - 1s 637us/step - loss: 0.3008 - accuracy: 0.8634\n",
      "Epoch 134/200\n",
      "796/796 [==============================] - 1s 648us/step - loss: 0.2906 - accuracy: 0.8721\n",
      "Epoch 135/200\n",
      "796/796 [==============================] - 1s 676us/step - loss: 0.2965 - accuracy: 0.8682\n",
      "Epoch 136/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.3032 - accuracy: 0.8686\n",
      "Epoch 137/200\n",
      "796/796 [==============================] - 1s 637us/step - loss: 0.2953 - accuracy: 0.8678\n",
      "Epoch 138/200\n",
      "796/796 [==============================] - 1s 644us/step - loss: 0.2960 - accuracy: 0.8653\n",
      "Epoch 139/200\n",
      "796/796 [==============================] - 1s 637us/step - loss: 0.3007 - accuracy: 0.8655\n",
      "Epoch 140/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.2965 - accuracy: 0.8718\n",
      "Epoch 141/200\n",
      "796/796 [==============================] - 1s 634us/step - loss: 0.2906 - accuracy: 0.8757\n",
      "Epoch 142/200\n",
      "796/796 [==============================] - 1s 647us/step - loss: 0.2972 - accuracy: 0.8561\n",
      "Epoch 143/200\n",
      "796/796 [==============================] - 1s 633us/step - loss: 0.2973 - accuracy: 0.8693\n",
      "Epoch 144/200\n",
      "796/796 [==============================] - 1s 661us/step - loss: 0.3072 - accuracy: 0.8600\n",
      "Epoch 145/200\n",
      "796/796 [==============================] - 1s 657us/step - loss: 0.3006 - accuracy: 0.8685\n",
      "Epoch 146/200\n",
      "796/796 [==============================] - 1s 641us/step - loss: 0.3031 - accuracy: 0.8617\n",
      "Epoch 147/200\n",
      "796/796 [==============================] - 1s 632us/step - loss: 0.2931 - accuracy: 0.8735\n",
      "Epoch 148/200\n",
      "796/796 [==============================] - 1s 638us/step - loss: 0.3124 - accuracy: 0.8657\n",
      "Epoch 149/200\n",
      "796/796 [==============================] - 1s 635us/step - loss: 0.2896 - accuracy: 0.8700\n",
      "Epoch 150/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.2929 - accuracy: 0.8697\n",
      "Epoch 151/200\n",
      "796/796 [==============================] - 1s 650us/step - loss: 0.2998 - accuracy: 0.8694\n",
      "Epoch 152/200\n",
      "796/796 [==============================] - 1s 645us/step - loss: 0.2961 - accuracy: 0.8711\n",
      "Epoch 153/200\n",
      "796/796 [==============================] - 1s 675us/step - loss: 0.3004 - accuracy: 0.8674\n",
      "Epoch 154/200\n",
      "796/796 [==============================] - 1s 665us/step - loss: 0.2976 - accuracy: 0.8635\n",
      "Epoch 155/200\n",
      "796/796 [==============================] - 1s 653us/step - loss: 0.2970 - accuracy: 0.8683\n",
      "Epoch 156/200\n",
      "796/796 [==============================] - 1s 640us/step - loss: 0.2890 - accuracy: 0.8630\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 1s 723us/step - loss: 0.2894 - accuracy: 0.8745\n",
      "Epoch 158/200\n",
      "796/796 [==============================] - 0s 618us/step - loss: 0.2923 - accuracy: 0.8763\n",
      "Epoch 159/200\n",
      "796/796 [==============================] - 1s 682us/step - loss: 0.3006 - accuracy: 0.8684\n",
      "Epoch 160/200\n",
      "796/796 [==============================] - 1s 640us/step - loss: 0.2911 - accuracy: 0.8641\n",
      "Epoch 161/200\n",
      "796/796 [==============================] - 0s 621us/step - loss: 0.2907 - accuracy: 0.8716\n",
      "Epoch 162/200\n",
      "796/796 [==============================] - 0s 590us/step - loss: 0.2843 - accuracy: 0.8757\n",
      "Epoch 163/200\n",
      "796/796 [==============================] - 0s 588us/step - loss: 0.2952 - accuracy: 0.8699\n",
      "Epoch 164/200\n",
      "796/796 [==============================] - 0s 592us/step - loss: 0.2853 - accuracy: 0.8777\n",
      "Epoch 165/200\n",
      "796/796 [==============================] - 0s 595us/step - loss: 0.2832 - accuracy: 0.8701\n",
      "Epoch 166/200\n",
      "796/796 [==============================] - 0s 594us/step - loss: 0.2788 - accuracy: 0.8778\n",
      "Epoch 167/200\n",
      "796/796 [==============================] - 0s 582us/step - loss: 0.2871 - accuracy: 0.8783\n",
      "Epoch 168/200\n",
      "796/796 [==============================] - 0s 594us/step - loss: 0.2894 - accuracy: 0.8734\n",
      "Epoch 169/200\n",
      "796/796 [==============================] - 0s 581us/step - loss: 0.2888 - accuracy: 0.8757\n",
      "Epoch 170/200\n",
      "796/796 [==============================] - 0s 584us/step - loss: 0.2957 - accuracy: 0.8601\n",
      "Epoch 171/200\n",
      "796/796 [==============================] - 0s 590us/step - loss: 0.2894 - accuracy: 0.8734\n",
      "Epoch 172/200\n",
      "796/796 [==============================] - 0s 607us/step - loss: 0.2873 - accuracy: 0.8664\n",
      "Epoch 173/200\n",
      "796/796 [==============================] - 0s 581us/step - loss: 0.2844 - accuracy: 0.8778\n",
      "Epoch 174/200\n",
      "796/796 [==============================] - 0s 599us/step - loss: 0.2884 - accuracy: 0.8724\n",
      "Epoch 175/200\n",
      "796/796 [==============================] - 0s 582us/step - loss: 0.2985 - accuracy: 0.8665\n",
      "Epoch 176/200\n",
      "796/796 [==============================] - 0s 598us/step - loss: 0.2872 - accuracy: 0.8693\n",
      "Epoch 177/200\n",
      "796/796 [==============================] - 0s 597us/step - loss: 0.2780 - accuracy: 0.8802\n",
      "Epoch 178/200\n",
      "796/796 [==============================] - 0s 582us/step - loss: 0.2912 - accuracy: 0.8715\n",
      "Epoch 179/200\n",
      "796/796 [==============================] - 0s 587us/step - loss: 0.2909 - accuracy: 0.8693\n",
      "Epoch 180/200\n",
      "796/796 [==============================] - 0s 586us/step - loss: 0.2865 - accuracy: 0.8708\n",
      "Epoch 181/200\n",
      "796/796 [==============================] - 0s 604us/step - loss: 0.2884 - accuracy: 0.8641\n",
      "Epoch 182/200\n",
      "796/796 [==============================] - 0s 618us/step - loss: 0.2866 - accuracy: 0.8704\n",
      "Epoch 183/200\n",
      "796/796 [==============================] - 0s 627us/step - loss: 0.2830 - accuracy: 0.8737\n",
      "Epoch 184/200\n",
      "796/796 [==============================] - 0s 604us/step - loss: 0.2921 - accuracy: 0.87240s - loss: 0.2927 - accuracy: 0.\n",
      "Epoch 185/200\n",
      "796/796 [==============================] - 0s 594us/step - loss: 0.2949 - accuracy: 0.8711\n",
      "Epoch 186/200\n",
      "796/796 [==============================] - 0s 585us/step - loss: 0.2799 - accuracy: 0.8759\n",
      "Epoch 187/200\n",
      "796/796 [==============================] - 0s 583us/step - loss: 0.2975 - accuracy: 0.8664\n",
      "Epoch 188/200\n",
      "796/796 [==============================] - 0s 592us/step - loss: 0.2767 - accuracy: 0.8810\n",
      "Epoch 189/200\n",
      "796/796 [==============================] - 0s 593us/step - loss: 0.2832 - accuracy: 0.8710\n",
      "Epoch 190/200\n",
      "796/796 [==============================] - 0s 582us/step - loss: 0.2843 - accuracy: 0.8694\n",
      "Epoch 191/200\n",
      "796/796 [==============================] - 0s 586us/step - loss: 0.2930 - accuracy: 0.8737\n",
      "Epoch 192/200\n",
      "796/796 [==============================] - 0s 587us/step - loss: 0.2887 - accuracy: 0.8711\n",
      "Epoch 193/200\n",
      "796/796 [==============================] - 0s 591us/step - loss: 0.2811 - accuracy: 0.8790\n",
      "Epoch 194/200\n",
      "796/796 [==============================] - 0s 591us/step - loss: 0.2939 - accuracy: 0.8656\n",
      "Epoch 195/200\n",
      "796/796 [==============================] - 0s 580us/step - loss: 0.2849 - accuracy: 0.8770\n",
      "Epoch 196/200\n",
      "796/796 [==============================] - 0s 619us/step - loss: 0.2809 - accuracy: 0.8776\n",
      "Epoch 197/200\n",
      "796/796 [==============================] - 0s 582us/step - loss: 0.2908 - accuracy: 0.8726\n",
      "Epoch 198/200\n",
      "796/796 [==============================] - 0s 592us/step - loss: 0.2905 - accuracy: 0.8710\n",
      "Epoch 199/200\n",
      "796/796 [==============================] - 1s 661us/step - loss: 0.2836 - accuracy: 0.8725\n",
      "Epoch 200/200\n",
      "796/796 [==============================] - 19s 24ms/step - loss: 0.2809 - accuracy: 0.8739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fe7cf750610>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'batch_size': [5, 10, 20], 'epochs': [50, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 453us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 490us/step - loss: 0.2631 - accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.883861243724823"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test_scaled, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 5, 'epochs': 200}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching on activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2(activation='relu'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, activation=activation, input_dim=9))\n",
    "    model.add(Dense(units=20, activation=activation))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = KerasClassifier(build_fn=create_model_2, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "activation_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model_2, param_grid=activation_grid, n_jobs=-1, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  24 | elapsed: 16.9min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed: 16.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.6146 - accuracy: 0.6632\n",
      "Epoch 2/200\n",
      "796/796 [==============================] - 1s 955us/step - loss: 0.5047 - accuracy: 0.7319\n",
      "Epoch 3/200\n",
      "796/796 [==============================] - 1s 893us/step - loss: 0.4728 - accuracy: 0.7371\n",
      "Epoch 4/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.4618 - accuracy: 0.7639\n",
      "Epoch 5/200\n",
      "796/796 [==============================] - 1s 928us/step - loss: 0.4431 - accuracy: 0.7823\n",
      "Epoch 6/200\n",
      "796/796 [==============================] - 1s 869us/step - loss: 0.4223 - accuracy: 0.7989\n",
      "Epoch 7/200\n",
      "796/796 [==============================] - 1s 877us/step - loss: 0.4229 - accuracy: 0.8033\n",
      "Epoch 8/200\n",
      "796/796 [==============================] - 1s 838us/step - loss: 0.4262 - accuracy: 0.7992\n",
      "Epoch 9/200\n",
      "796/796 [==============================] - 1s 901us/step - loss: 0.4154 - accuracy: 0.8068\n",
      "Epoch 10/200\n",
      "796/796 [==============================] - 1s 967us/step - loss: 0.3912 - accuracy: 0.8151\n",
      "Epoch 11/200\n",
      "796/796 [==============================] - 1s 896us/step - loss: 0.3977 - accuracy: 0.8280\n",
      "Epoch 12/200\n",
      "796/796 [==============================] - 1s 806us/step - loss: 0.3847 - accuracy: 0.8276\n",
      "Epoch 13/200\n",
      "796/796 [==============================] - 1s 832us/step - loss: 0.3955 - accuracy: 0.8120\n",
      "Epoch 14/200\n",
      "796/796 [==============================] - 1s 912us/step - loss: 0.3928 - accuracy: 0.8250\n",
      "Epoch 15/200\n",
      "796/796 [==============================] - 1s 814us/step - loss: 0.3836 - accuracy: 0.8261\n",
      "Epoch 16/200\n",
      "796/796 [==============================] - 1s 849us/step - loss: 0.3676 - accuracy: 0.8399\n",
      "Epoch 17/200\n",
      "796/796 [==============================] - 1s 866us/step - loss: 0.3739 - accuracy: 0.8257\n",
      "Epoch 18/200\n",
      "796/796 [==============================] - 1s 869us/step - loss: 0.3681 - accuracy: 0.8365\n",
      "Epoch 19/200\n",
      "796/796 [==============================] - 1s 856us/step - loss: 0.3619 - accuracy: 0.8368\n",
      "Epoch 20/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3670 - accuracy: 0.8372\n",
      "Epoch 21/200\n",
      "796/796 [==============================] - 1s 993us/step - loss: 0.3721 - accuracy: 0.8388\n",
      "Epoch 22/200\n",
      "796/796 [==============================] - 1s 852us/step - loss: 0.3492 - accuracy: 0.8404\n",
      "Epoch 23/200\n",
      "796/796 [==============================] - 1s 936us/step - loss: 0.3650 - accuracy: 0.8422\n",
      "Epoch 24/200\n",
      "796/796 [==============================] - 1s 898us/step - loss: 0.3489 - accuracy: 0.8471\n",
      "Epoch 25/200\n",
      "796/796 [==============================] - 1s 821us/step - loss: 0.3373 - accuracy: 0.8562\n",
      "Epoch 26/200\n",
      "796/796 [==============================] - 1s 852us/step - loss: 0.3447 - accuracy: 0.8471\n",
      "Epoch 27/200\n",
      "796/796 [==============================] - 1s 823us/step - loss: 0.3430 - accuracy: 0.8491\n",
      "Epoch 28/200\n",
      "796/796 [==============================] - 1s 842us/step - loss: 0.3309 - accuracy: 0.8585\n",
      "Epoch 29/200\n",
      "796/796 [==============================] - 1s 923us/step - loss: 0.3347 - accuracy: 0.8506\n",
      "Epoch 30/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3468 - accuracy: 0.8450\n",
      "Epoch 31/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3402 - accuracy: 0.8478\n",
      "Epoch 32/200\n",
      "796/796 [==============================] - 1s 974us/step - loss: 0.3465 - accuracy: 0.8380\n",
      "Epoch 33/200\n",
      "796/796 [==============================] - 1s 912us/step - loss: 0.3267 - accuracy: 0.8652\n",
      "Epoch 34/200\n",
      "796/796 [==============================] - 1s 965us/step - loss: 0.3451 - accuracy: 0.8462\n",
      "Epoch 35/200\n",
      "796/796 [==============================] - 1s 921us/step - loss: 0.3255 - accuracy: 0.8585\n",
      "Epoch 36/200\n",
      "796/796 [==============================] - 1s 871us/step - loss: 0.3336 - accuracy: 0.8525\n",
      "Epoch 37/200\n",
      "796/796 [==============================] - 1s 903us/step - loss: 0.3310 - accuracy: 0.8572\n",
      "Epoch 38/200\n",
      "796/796 [==============================] - 1s 811us/step - loss: 0.3406 - accuracy: 0.8485\n",
      "Epoch 39/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3430 - accuracy: 0.8437\n",
      "Epoch 40/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3353 - accuracy: 0.8475\n",
      "Epoch 41/200\n",
      "796/796 [==============================] - 1s 937us/step - loss: 0.3219 - accuracy: 0.8551\n",
      "Epoch 42/200\n",
      "796/796 [==============================] - 1s 835us/step - loss: 0.3266 - accuracy: 0.8570\n",
      "Epoch 43/200\n",
      "796/796 [==============================] - 1s 799us/step - loss: 0.3184 - accuracy: 0.8659\n",
      "Epoch 44/200\n",
      "796/796 [==============================] - 1s 961us/step - loss: 0.3173 - accuracy: 0.86800s - loss: 0.3152 - accura\n",
      "Epoch 45/200\n",
      "796/796 [==============================] - 1s 963us/step - loss: 0.3139 - accuracy: 0.8630\n",
      "Epoch 46/200\n",
      "796/796 [==============================] - 1s 832us/step - loss: 0.3105 - accuracy: 0.8614\n",
      "Epoch 47/200\n",
      "796/796 [==============================] - 1s 879us/step - loss: 0.3190 - accuracy: 0.8593\n",
      "Epoch 48/200\n",
      "796/796 [==============================] - 1s 944us/step - loss: 0.3148 - accuracy: 0.87120s - loss: 0.3103 - \n",
      "Epoch 49/200\n",
      "796/796 [==============================] - 1s 918us/step - loss: 0.3300 - accuracy: 0.8557\n",
      "Epoch 50/200\n",
      "796/796 [==============================] - 1s 927us/step - loss: 0.3208 - accuracy: 0.8606\n",
      "Epoch 51/200\n",
      "796/796 [==============================] - 1s 855us/step - loss: 0.3138 - accuracy: 0.8637\n",
      "Epoch 52/200\n",
      "796/796 [==============================] - 1s 894us/step - loss: 0.3139 - accuracy: 0.8659\n",
      "Epoch 53/200\n",
      "796/796 [==============================] - 1s 915us/step - loss: 0.3233 - accuracy: 0.8571\n",
      "Epoch 54/200\n",
      "796/796 [==============================] - 1s 843us/step - loss: 0.3226 - accuracy: 0.8641\n",
      "Epoch 55/200\n",
      "796/796 [==============================] - 1s 979us/step - loss: 0.3189 - accuracy: 0.8563\n",
      "Epoch 56/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3204 - accuracy: 0.8565\n",
      "Epoch 57/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3269 - accuracy: 0.8679\n",
      "Epoch 58/200\n",
      "796/796 [==============================] - 1s 908us/step - loss: 0.3144 - accuracy: 0.8629\n",
      "Epoch 59/200\n",
      "796/796 [==============================] - 1s 895us/step - loss: 0.3266 - accuracy: 0.85580s - loss: 0.3352 - \n",
      "Epoch 60/200\n",
      "796/796 [==============================] - 1s 892us/step - loss: 0.3065 - accuracy: 0.86990s - loss: 0.294\n",
      "Epoch 61/200\n",
      "796/796 [==============================] - 1s 798us/step - loss: 0.3227 - accuracy: 0.8600\n",
      "Epoch 62/200\n",
      "796/796 [==============================] - 1s 777us/step - loss: 0.3105 - accuracy: 0.8639\n",
      "Epoch 63/200\n",
      "796/796 [==============================] - 1s 791us/step - loss: 0.3122 - accuracy: 0.8619\n",
      "Epoch 64/200\n",
      "796/796 [==============================] - 1s 827us/step - loss: 0.3114 - accuracy: 0.8537\n",
      "Epoch 65/200\n",
      "796/796 [==============================] - 1s 797us/step - loss: 0.3084 - accuracy: 0.8717\n",
      "Epoch 66/200\n",
      "796/796 [==============================] - 1s 834us/step - loss: 0.3105 - accuracy: 0.8620\n",
      "Epoch 67/200\n",
      "796/796 [==============================] - 1s 917us/step - loss: 0.3084 - accuracy: 0.8738\n",
      "Epoch 68/200\n",
      "796/796 [==============================] - 1s 851us/step - loss: 0.2996 - accuracy: 0.8748\n",
      "Epoch 69/200\n",
      "796/796 [==============================] - 1s 852us/step - loss: 0.3084 - accuracy: 0.8668\n",
      "Epoch 70/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3065 - accuracy: 0.8710\n",
      "Epoch 71/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3051 - accuracy: 0.8751\n",
      "Epoch 72/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3128 - accuracy: 0.8611\n",
      "Epoch 73/200\n",
      "796/796 [==============================] - 1s 976us/step - loss: 0.3114 - accuracy: 0.8691\n",
      "Epoch 74/200\n",
      "796/796 [==============================] - 1s 869us/step - loss: 0.3065 - accuracy: 0.8697\n",
      "Epoch 75/200\n",
      "796/796 [==============================] - 1s 878us/step - loss: 0.3205 - accuracy: 0.8580\n",
      "Epoch 76/200\n",
      "796/796 [==============================] - 1s 914us/step - loss: 0.3039 - accuracy: 0.8643\n",
      "Epoch 77/200\n",
      "796/796 [==============================] - 1s 813us/step - loss: 0.3092 - accuracy: 0.8750\n",
      "Epoch 78/200\n",
      "796/796 [==============================] - 1s 833us/step - loss: 0.3240 - accuracy: 0.8527\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 1s 818us/step - loss: 0.3019 - accuracy: 0.8710\n",
      "Epoch 80/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3084 - accuracy: 0.8662\n",
      "Epoch 81/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2939 - accuracy: 0.8703\n",
      "Epoch 82/200\n",
      "796/796 [==============================] - 1s 917us/step - loss: 0.2835 - accuracy: 0.8856\n",
      "Epoch 83/200\n",
      "796/796 [==============================] - 1s 902us/step - loss: 0.3296 - accuracy: 0.8589\n",
      "Epoch 84/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3078 - accuracy: 0.8654\n",
      "Epoch 85/200\n",
      "796/796 [==============================] - 1s 886us/step - loss: 0.2927 - accuracy: 0.8724\n",
      "Epoch 86/200\n",
      "796/796 [==============================] - 1s 860us/step - loss: 0.2971 - accuracy: 0.8731\n",
      "Epoch 87/200\n",
      "796/796 [==============================] - 1s 885us/step - loss: 0.2981 - accuracy: 0.8697\n",
      "Epoch 88/200\n",
      "796/796 [==============================] - 1s 935us/step - loss: 0.3121 - accuracy: 0.8675\n",
      "Epoch 89/200\n",
      "796/796 [==============================] - 1s 905us/step - loss: 0.2923 - accuracy: 0.8796\n",
      "Epoch 90/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3035 - accuracy: 0.8682\n",
      "Epoch 91/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3064 - accuracy: 0.8648\n",
      "Epoch 92/200\n",
      "796/796 [==============================] - 1s 903us/step - loss: 0.3056 - accuracy: 0.86290s - loss: 0.3084 \n",
      "Epoch 93/200\n",
      "796/796 [==============================] - 1s 816us/step - loss: 0.3031 - accuracy: 0.8660\n",
      "Epoch 94/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3017 - accuracy: 0.8635\n",
      "Epoch 95/200\n",
      "796/796 [==============================] - 1s 823us/step - loss: 0.2971 - accuracy: 0.8764\n",
      "Epoch 96/200\n",
      "796/796 [==============================] - 1s 869us/step - loss: 0.3024 - accuracy: 0.86870s - loss: 0.3027 - accuracy: 0.86\n",
      "Epoch 97/200\n",
      "796/796 [==============================] - 1s 999us/step - loss: 0.3006 - accuracy: 0.8680\n",
      "Epoch 98/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3056 - accuracy: 0.8651\n",
      "Epoch 99/200\n",
      "796/796 [==============================] - 1s 929us/step - loss: 0.2865 - accuracy: 0.8705\n",
      "Epoch 100/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2855 - accuracy: 0.8751\n",
      "Epoch 101/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2826 - accuracy: 0.8789: 0s - loss: 0.2785 - accuracy\n",
      "Epoch 102/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2917 - accuracy: 0.8731\n",
      "Epoch 103/200\n",
      "796/796 [==============================] - 1s 961us/step - loss: 0.3030 - accuracy: 0.8671\n",
      "Epoch 104/200\n",
      "796/796 [==============================] - 1s 870us/step - loss: 0.2898 - accuracy: 0.8784\n",
      "Epoch 105/200\n",
      "796/796 [==============================] - 1s 856us/step - loss: 0.2915 - accuracy: 0.8700\n",
      "Epoch 106/200\n",
      "796/796 [==============================] - 1s 932us/step - loss: 0.2990 - accuracy: 0.8736\n",
      "Epoch 107/200\n",
      "796/796 [==============================] - 1s 925us/step - loss: 0.3005 - accuracy: 0.8639\n",
      "Epoch 108/200\n",
      "796/796 [==============================] - 1s 997us/step - loss: 0.3023 - accuracy: 0.8656\n",
      "Epoch 109/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2929 - accuracy: 0.8695\n",
      "Epoch 110/200\n",
      "796/796 [==============================] - 1s 949us/step - loss: 0.3020 - accuracy: 0.8664\n",
      "Epoch 111/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2890 - accuracy: 0.8785\n",
      "Epoch 112/200\n",
      "796/796 [==============================] - 1s 977us/step - loss: 0.2825 - accuracy: 0.8857\n",
      "Epoch 113/200\n",
      "796/796 [==============================] - 1s 992us/step - loss: 0.2865 - accuracy: 0.8793\n",
      "Epoch 114/200\n",
      "796/796 [==============================] - 1s 868us/step - loss: 0.2934 - accuracy: 0.8690\n",
      "Epoch 115/200\n",
      "796/796 [==============================] - 1s 948us/step - loss: 0.2888 - accuracy: 0.8716\n",
      "Epoch 116/200\n",
      "796/796 [==============================] - 1s 983us/step - loss: 0.2917 - accuracy: 0.8689\n",
      "Epoch 117/200\n",
      "796/796 [==============================] - 1s 923us/step - loss: 0.2892 - accuracy: 0.8725\n",
      "Epoch 118/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2846 - accuracy: 0.8780\n",
      "Epoch 119/200\n",
      "796/796 [==============================] - 1s 937us/step - loss: 0.3031 - accuracy: 0.8627\n",
      "Epoch 120/200\n",
      "796/796 [==============================] - 1s 867us/step - loss: 0.2889 - accuracy: 0.8764\n",
      "Epoch 121/200\n",
      "796/796 [==============================] - 1s 907us/step - loss: 0.2919 - accuracy: 0.8709\n",
      "Epoch 122/200\n",
      "796/796 [==============================] - 1s 849us/step - loss: 0.2948 - accuracy: 0.8726\n",
      "Epoch 123/200\n",
      "796/796 [==============================] - 1s 903us/step - loss: 0.2884 - accuracy: 0.8765\n",
      "Epoch 124/200\n",
      "796/796 [==============================] - 1s 896us/step - loss: 0.2804 - accuracy: 0.8779\n",
      "Epoch 125/200\n",
      "796/796 [==============================] - 1s 815us/step - loss: 0.2960 - accuracy: 0.8656\n",
      "Epoch 126/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2885 - accuracy: 0.8735\n",
      "Epoch 127/200\n",
      "796/796 [==============================] - 1s 895us/step - loss: 0.2979 - accuracy: 0.8667\n",
      "Epoch 128/200\n",
      "796/796 [==============================] - 1s 939us/step - loss: 0.2946 - accuracy: 0.8698\n",
      "Epoch 129/200\n",
      "796/796 [==============================] - 1s 894us/step - loss: 0.2952 - accuracy: 0.8706\n",
      "Epoch 130/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.3001 - accuracy: 0.8635: 0s - loss: 0.3048 -  - ETA: 0s - loss: 0.3008 - accuracy: \n",
      "Epoch 131/200\n",
      "796/796 [==============================] - 1s 834us/step - loss: 0.2972 - accuracy: 0.8654\n",
      "Epoch 132/200\n",
      "796/796 [==============================] - 1s 825us/step - loss: 0.2956 - accuracy: 0.8666\n",
      "Epoch 133/200\n",
      "796/796 [==============================] - 1s 856us/step - loss: 0.2951 - accuracy: 0.8722\n",
      "Epoch 134/200\n",
      "796/796 [==============================] - 1s 963us/step - loss: 0.3036 - accuracy: 0.8741\n",
      "Epoch 135/200\n",
      "796/796 [==============================] - 1s 882us/step - loss: 0.2909 - accuracy: 0.8680\n",
      "Epoch 136/200\n",
      "796/796 [==============================] - 1s 935us/step - loss: 0.2838 - accuracy: 0.8772\n",
      "Epoch 137/200\n",
      "796/796 [==============================] - 1s 999us/step - loss: 0.2803 - accuracy: 0.8807\n",
      "Epoch 138/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2958 - accuracy: 0.8689\n",
      "Epoch 139/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2839 - accuracy: 0.8709\n",
      "Epoch 140/200\n",
      "796/796 [==============================] - 1s 893us/step - loss: 0.2879 - accuracy: 0.8752\n",
      "Epoch 141/200\n",
      "796/796 [==============================] - 1s 788us/step - loss: 0.2841 - accuracy: 0.8756\n",
      "Epoch 142/200\n",
      "796/796 [==============================] - 1s 805us/step - loss: 0.2870 - accuracy: 0.8744\n",
      "Epoch 143/200\n",
      "796/796 [==============================] - 1s 810us/step - loss: 0.2906 - accuracy: 0.8676\n",
      "Epoch 144/200\n",
      "796/796 [==============================] - 1s 776us/step - loss: 0.2821 - accuracy: 0.8786\n",
      "Epoch 145/200\n",
      "796/796 [==============================] - 1s 777us/step - loss: 0.2856 - accuracy: 0.8748\n",
      "Epoch 146/200\n",
      "796/796 [==============================] - 1s 789us/step - loss: 0.2917 - accuracy: 0.8724\n",
      "Epoch 147/200\n",
      "796/796 [==============================] - 1s 787us/step - loss: 0.2763 - accuracy: 0.8832\n",
      "Epoch 148/200\n",
      "796/796 [==============================] - 1s 848us/step - loss: 0.3034 - accuracy: 0.8634\n",
      "Epoch 149/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2921 - accuracy: 0.8716\n",
      "Epoch 150/200\n",
      "796/796 [==============================] - 1s 907us/step - loss: 0.2872 - accuracy: 0.8811\n",
      "Epoch 151/200\n",
      "796/796 [==============================] - 1s 798us/step - loss: 0.2843 - accuracy: 0.8826\n",
      "Epoch 152/200\n",
      "796/796 [==============================] - 1s 807us/step - loss: 0.3073 - accuracy: 0.8631\n",
      "Epoch 153/200\n",
      "796/796 [==============================] - 1s 870us/step - loss: 0.2957 - accuracy: 0.8643\n",
      "Epoch 154/200\n",
      "796/796 [==============================] - 1s 973us/step - loss: 0.2851 - accuracy: 0.8757\n",
      "Epoch 155/200\n",
      "796/796 [==============================] - 1s 857us/step - loss: 0.2825 - accuracy: 0.8726\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "796/796 [==============================] - 1s 812us/step - loss: 0.2845 - accuracy: 0.8770\n",
      "Epoch 157/200\n",
      "796/796 [==============================] - 1s 879us/step - loss: 0.2895 - accuracy: 0.87530s - loss: 0.2915 - accura\n",
      "Epoch 158/200\n",
      "796/796 [==============================] - 1s 968us/step - loss: 0.2857 - accuracy: 0.8766\n",
      "Epoch 159/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2969 - accuracy: 0.8596\n",
      "Epoch 160/200\n",
      "796/796 [==============================] - 1s 842us/step - loss: 0.2905 - accuracy: 0.8677\n",
      "Epoch 161/200\n",
      "796/796 [==============================] - 1s 796us/step - loss: 0.2794 - accuracy: 0.8790\n",
      "Epoch 162/200\n",
      "796/796 [==============================] - 1s 800us/step - loss: 0.2799 - accuracy: 0.8747\n",
      "Epoch 163/200\n",
      "796/796 [==============================] - 1s 793us/step - loss: 0.2776 - accuracy: 0.8799\n",
      "Epoch 164/200\n",
      "796/796 [==============================] - 1s 785us/step - loss: 0.2894 - accuracy: 0.8750\n",
      "Epoch 165/200\n",
      "796/796 [==============================] - 1s 921us/step - loss: 0.2925 - accuracy: 0.8680\n",
      "Epoch 166/200\n",
      "796/796 [==============================] - 1s 795us/step - loss: 0.2761 - accuracy: 0.8819\n",
      "Epoch 167/200\n",
      "796/796 [==============================] - 1s 787us/step - loss: 0.2817 - accuracy: 0.8750\n",
      "Epoch 168/200\n",
      "796/796 [==============================] - 1s 961us/step - loss: 0.2809 - accuracy: 0.8707\n",
      "Epoch 169/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.8845\n",
      "Epoch 170/200\n",
      "796/796 [==============================] - 1s 931us/step - loss: 0.2804 - accuracy: 0.8749\n",
      "Epoch 171/200\n",
      "796/796 [==============================] - 1s 905us/step - loss: 0.2906 - accuracy: 0.8809\n",
      "Epoch 172/200\n",
      "796/796 [==============================] - 1s 779us/step - loss: 0.2899 - accuracy: 0.8815\n",
      "Epoch 173/200\n",
      "796/796 [==============================] - 1s 783us/step - loss: 0.2880 - accuracy: 0.8766\n",
      "Epoch 174/200\n",
      "796/796 [==============================] - 1s 906us/step - loss: 0.2686 - accuracy: 0.8869\n",
      "Epoch 175/200\n",
      "796/796 [==============================] - 1s 942us/step - loss: 0.2714 - accuracy: 0.8905\n",
      "Epoch 176/200\n",
      "796/796 [==============================] - 1s 978us/step - loss: 0.2780 - accuracy: 0.8770\n",
      "Epoch 177/200\n",
      "796/796 [==============================] - 1s 890us/step - loss: 0.2773 - accuracy: 0.8784\n",
      "Epoch 178/200\n",
      "796/796 [==============================] - 1s 934us/step - loss: 0.2966 - accuracy: 0.8699\n",
      "Epoch 179/200\n",
      "796/796 [==============================] - 1s 925us/step - loss: 0.2851 - accuracy: 0.8804\n",
      "Epoch 180/200\n",
      "796/796 [==============================] - 1s 922us/step - loss: 0.2810 - accuracy: 0.8757\n",
      "Epoch 181/200\n",
      "796/796 [==============================] - 1s 817us/step - loss: 0.2853 - accuracy: 0.8742\n",
      "Epoch 182/200\n",
      "796/796 [==============================] - 1s 780us/step - loss: 0.2789 - accuracy: 0.8783\n",
      "Epoch 183/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2686 - accuracy: 0.8832\n",
      "Epoch 184/200\n",
      "796/796 [==============================] - 1s 884us/step - loss: 0.2858 - accuracy: 0.8761\n",
      "Epoch 185/200\n",
      "796/796 [==============================] - 1s 884us/step - loss: 0.2838 - accuracy: 0.8764\n",
      "Epoch 186/200\n",
      "796/796 [==============================] - 1s 807us/step - loss: 0.2790 - accuracy: 0.8711\n",
      "Epoch 187/200\n",
      "796/796 [==============================] - 1s 854us/step - loss: 0.2722 - accuracy: 0.8856\n",
      "Epoch 188/200\n",
      "796/796 [==============================] - 1s 961us/step - loss: 0.2767 - accuracy: 0.8802\n",
      "Epoch 189/200\n",
      "796/796 [==============================] - 1s 910us/step - loss: 0.2925 - accuracy: 0.8699\n",
      "Epoch 190/200\n",
      "796/796 [==============================] - 1s 933us/step - loss: 0.2824 - accuracy: 0.8768\n",
      "Epoch 191/200\n",
      "796/796 [==============================] - 1s 812us/step - loss: 0.2773 - accuracy: 0.8811\n",
      "Epoch 192/200\n",
      "796/796 [==============================] - 1s 883us/step - loss: 0.2942 - accuracy: 0.8708\n",
      "Epoch 193/200\n",
      "796/796 [==============================] - 1s 819us/step - loss: 0.2775 - accuracy: 0.8733\n",
      "Epoch 194/200\n",
      "796/796 [==============================] - 1s 859us/step - loss: 0.2929 - accuracy: 0.8676\n",
      "Epoch 195/200\n",
      "796/796 [==============================] - 1s 846us/step - loss: 0.2781 - accuracy: 0.8698\n",
      "Epoch 196/200\n",
      "796/796 [==============================] - 1s 800us/step - loss: 0.3010 - accuracy: 0.8662\n",
      "Epoch 197/200\n",
      "796/796 [==============================] - 1s 981us/step - loss: 0.2899 - accuracy: 0.8705\n",
      "Epoch 198/200\n",
      "796/796 [==============================] - 1s 844us/step - loss: 0.2595 - accuracy: 0.88970s - loss: 0.2592 - accuracy: 0.88\n",
      "Epoch 199/200\n",
      "796/796 [==============================] - 1s 922us/step - loss: 0.2870 - accuracy: 0.8762\n",
      "Epoch 200/200\n",
      "796/796 [==============================] - 1s 1ms/step - loss: 0.2789 - accuracy: 0.8782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fe7b0770b50>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['softmax', 'softplus', 'softsign',\n",
       "                                        'relu', 'tanh', 'sigmoid',\n",
       "                                        'hard_sigmoid', 'linear']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heads up - this takes a long time to run! In retrospect I should have done these in the opposide order, \n",
    "# or just ran this one with a smaller number of epochs!\n",
    "\n",
    "grid.fit(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fe7cfe13af0>\n",
      "266/266 [==============================] - 0s 596us/step - loss: 0.2615 - accuracy: 0.8846\n",
      "0.8846153616905212\n"
     ]
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "print(model)\n",
    "print(model.score(X_test_scaled, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'weakref' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-44b6d98a018a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../saved_models/deep_learning_model.sav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_setter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_setter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate_setter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUILD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call unbound method with explicit self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemoize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_setitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36m_batch_setitems\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m                     \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                 \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSETITEMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                     \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                     \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'weakref' object"
     ]
    }
   ],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = '../saved_models/deep_learning_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5a3c3ed97efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../saved_models/deep_learning_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "model.save(\"../saved_models/deep_learning_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graders - I know I  couldn't get this to save, but I still thought it was fun to include!"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
